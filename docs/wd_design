Warpdrive architecture design
=============================

Revision
--------
- Revision 0.1 2019.11.26 Sherlock init

1. Introduction
---------------
 Warpdrive is an accelerator software architecture to help vendors to use their
 hardware accelerator in user space easily and efficiently. It includes a kernel
 driver named UACCE and a user space libary named libwd.

 libwd provides a wrapper of basic UACCE user space interfaces, they will be
 a set of help functions. And libwd offers a set of APIs based on specific
 algorithms to users, who could use this set of APIs to do specific task without
 known low level implementations. libwd offers a register interface to let
 hardware vendors to register their own user space driver, which could use above
 help functions to do UACCE related work.

 The key point of Warpdrive is that it is based on Linux SVA technology, which
 make device in user space to share a same virtual address space with CPU.

 This document focuses on the design of libwd.

2. UACCE user space API
-----------------------

 As the kernel driver of warpdrive, UACCE offers a set of API between kernel
 and user space.

 As UACCE driver is still under upstreaming, latest APIs of UACCE can be found
 in: https://lkml.org/lkml/2019/11/22/1728. Documents "uacce.rst" and
 "sysfs-driver-uacce" are introduced in this patchset. And a UACCE design
 document also can be found in:
 https://github.com/hisilicon/dev-docs/tree/master/warpdrive/wd_design.rst
 (private currently)

 This basic idea of is UACCE driver is that a char device will be created for
 an accelerator device, which attributes will be showed in syfs, like
 /sys/class/uacce/<device>/<attr_files>. After openning this char device once,
 user will get a channel to access the resource of this accelerator device.
 User can configure above channel by ioctl of this openned fd, and mmap hardware
 resource, like MMIO or queue to user space.

3. Overall Design
-----------------
```
           +--------------+
           | wd alg layer |
           +--------------+
                   ^
                   |
           +----------------+       +----------------------------+
           | vendor drivers |------>| possible vendor driver lib |
           +----------------+       +----------------------------+
                |       |
                |       v
                |   +-------------------+
                |   | wd help functions |
                |   +-------------------+
                |       |
                v       v
           +------------------------------+
           | memory, mmio, fd, sysfs, dev |
           +------------------------------+
```
 libwd includes wd help functions and wd algorigthm layer. wd help functions
 are a set of wrapper functions about UACCE user space API. Vendor drivers
 could use these basic help functions to get wd_chan, mmap device MMIO etc.
 Refer to "6. wd help functions" for details. wd algorigthm layer provides
 specific algorithms APIs for user, which is called North API, and offers
 register interface for vendor drivers to register, which is called South API.

 1. memory type

   The memory which is use by user to store data can be defined as SVA type or
   no SVA type. User need not to know this concept, to descript the design,
   memory type is mentioned here.

   If system supports SVA(This can be detected by vendor driver), address from
   user can be used directly in wd alg layer, vendor driver and set into
   hardware.

   If system does not support SVA, data in the address of user should be copied
   to an internal buffer which can be accessed by hardware, and then processed
   by hardware. The process of copy is done in vendor driver, user know nothing
   about this. Of cause, copy data into an internal buffer will make performance
   worse.

   NOTE: libwd is mainly focus on SVA memory type. For the system which does not
         support SVA, no sva memory can be used, HOWEVER, NO SVA IS NOT LONG
	 TERM SUPPORT.

 2. operation type

   Libwd supports both synchronous and asynchronous operations. North API will
   offer both sync and async interface for specific algorithms.

   - synchronous operation

     In this case, the function does not return until the operation is complete.

   - asynchronous operation

     In this case, Control returns to user once request has been sent to
     hardware, and a callback is invoked when the hardware completes the
     operation. User is responsible for creating a polling thread to invoke
     related callback. Detail APIs will be mentioned in "4. North API".

4. North API
------------

 1. general alg

   - struct wd_alg_ctx {

     };

 2. compression/decompression

   - struct wd_alg_comp_ctx {
	   struct wd_alg_ctx base;
     };

     wd compression/decompression context, which is used as a handler to do
     compression/decompression job.

   - struct wd_alg_comp_req {
	 /* If cb is NULL, it is sync operation */
         void (*cb)(struct wd_alg_comp_req *req, int err);
	 /* If ture, statefull mode, otherwise stateless mode */
	 bool stateful;
     };

     wd compression/decompression request, which is used as a wd compression/
     decompression request. User should firstly allocate a request from one
     wd_alg_comp_ctx, fill parameters of this request, and send this request
     by below wd_alg_comp/wd_alg_decomp.

   - struct wd_alg_comp_ctx *wd_alg_alloc_comp_ctx(stuct wd_alg_comp_param param)

     This can be used to allocate one wd_alg_comp_ctx.

   - void wd_alg_free_comp_ctx(struct wd_alg_comp_ctx *ctx)

     Free wd_alg_comp_ctx.

   - int wd_alg_comp(struct wd_alg_comp_req *req)

     Send a compression request to its related wd_alg_comp_ctx. It supports
     multiple threads sending requests to one context, related work should be
     done in vendor driver. The stateful mode or stateless mode should be set
     in req, which should be supported in vendor driver.

   - int wd_alg_decomp(struct wd_alg_comp_req *req)

     Sent a decompression request, other same as above.

   - struct wd_alg_comp_req *wd_alg_alloc_acomp_req(struct wd_alg_comp_ctx *ctx)

     Allocate a compression/decompression request from one wd_alg_comp_ctx.

   - void wd_alg_free_acomp_req(struct wd_alg_comp_req *req)

     Free one wd_alg_comp_req;

   - int wd_alg_comp_poll(struct wd_alg_comp_ctx *ctx, int num)

     In async mode, user can use it to pool num completed request in ctx.

5. South API
------------

 1. general alg

   - struct wd_alg_base {
             char alg_name[WD_ALG_MAX_ALG_NAME];
	     char drv_name[WD_ALG_MAX_DRV_NAME];
     };

 2. compression/decompression

   - int wd_alg_comp_register(const struct wd_alg_comp *alg)

     Register a driver for a compression/decompression hardware engine.

   - void wd_alg_comp_unregister(const struct wd_alg_comp *alg)

     Unregister a compression/decompression hardware engine.

   - struct wd_alg_comp {
             int (*init)(struct wd_alg_comp_ctx *ctx);
             void (*exit)(struct wd_alg_comp_ctx *ctx);
             int (*compress)(struct wd_alg_comp_req *req);
             int (*decompress)(struct wd_alg_comp_req *req);
             int (*poll)(struct wd_alg_comp_ctx *ctx, num);
	     struct wd_alg base;
     };

6. wd help functions
--------------------

 - struct uacce_dev {
           int node_id;
           bool is_sva;
           int flags;
           unsigned long qfrs_offset[UACCE_QFRT_MAX];
   };

 - struct wd_chan {
           struct uacce_dev *dev;
           int fd;
           char dev_path[PATH_STR_SIZE];
           void *ss_va;
           void *ss_pa;
   };
 
 - struct wd_dev_type {
   }

 - struct wd_chan *wd_request_chan(struct wd_dev_type dev_type)

 - void wd_release_chan(struct wd_chan *chan)

 - int wd_chan_mmap(struct wd_chan *chan, int type)

 - void wd_chan_unmap(struct wd_chan *chan, int type)

 - void *wd_reserve_memory(struct wd_chan *chan, size_t size)

   NOTE: only use in NO SVA mode, not long term support.

7. Implementation
-----------------

 Same as kernel crypto subsystem, but much simpler.
 (to do: ...)

8. Example
----------

 - HiSlicon KunPeng920 ZIP engine

   ZIP engine uses QM module to do queue managerment. So the operations about
   QM can be put in a lib.

   As mentioned above, ZIP engine driver only need to implement callbacks in
   wd_alg_comp.

   init: Get MMIO/DUS, get ss region if no SVA; Other configures.
         To handle async, driver should maintain a request cache to store
	 request info including callback.

	 If in no SVA mode, reserve a ss region.

   exit: Free above.

   compress: Convert wd_comp_req to a ZIP BD, send, update QM info.
             If sync, wait to check cq, if async, return.

	     If in SVA mode, use address passed by user; if in no SVA mode,
	     should copy user data to ss region, then pass address of ss_pa
	     to hardware BD.

   decompress: Same above.

   poll: Poll cq, then find related request cache to trigger callback.

   NOTE: Other accelerators like HPRE/SEC in HiSilicon KunPeng920 use QM too,
         can consider to use one same driver for them.

Appendix
========
